---
title: "FIN7030:Algorithmic trading and investment"
subtitle: "High performance cloud computing in finance"
author: "Barry Quinn"
date: "20/12/2020 (updated `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["fonts.css","default", "mycssblend.css"]
    lib_dir: libs
    nature:
      countdown: 120000
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      ratio: "16:9"
      beforeInit: "https://platform.twitter.com/widgets.js"
    seal: true
    includes:
      in_header: "mathjax-equation-numbers.html" 
---

```{r setup, include=FALSE}
library(htmltools)
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(tidyverse)
library(babynames)
library(fontawesome) 
library(DiagrammeR)
library(xaringanExtra)
library(timevis)
xaringanExtra::use_logo(image_url = "img/redlogo.png")
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now)
      # return a character string to show the time
      paste("Time for this code chunk to run:", res)
    }
  }
}))
xaringanExtra::use_tile_view()
xaringanExtra::use_webcam()
xaringanExtra::use_broadcast()
xaringanExtra::use_panelset()
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

```

layout: true
  
<div class="my-footer"><span>quinference.com</span></div>

---
class:inverse
# Outline 
- .salt[What is cloud computing?]
- .fat[Introduction to the Q-RaP]
- .acid[Taxonomy of parallel computing]
- .heat[Performance computing in Python]
- .salt[The economics of AI in business]
---

class:middle
background-image: url(img/recticulated_python.png)
background-size: cover

## Introduction
.large[
- This course will expose you to the flexibility of cloud computing
- We will learn how to build agile analytics by combining `r fa(name="r-project")` `r fa(name="plus")` `r fa(name="python")` 

- Financial institutions have a long history of heavily investing in technology for gaining market share and defending their current position
- The democratisation of computing processing power by cloud providers, has lead to an explosion in financial machine learning applications.
- Today technology that would have costed millions 20 years ago can be rented for thousand from these cloud providers
]

>Meriwther spent $20 million on a state-of-the-art computer system and hired a crack team of financial engineers to run the show at LTCM..... 
`r tufte::quote_footer('Scott Patterson, The Quants, 2010')`
---
class: middle
# What is cloud computing ?

- .heat[Cloud computing shares many of the similarities of electricity]

--

- .large[In the early days of electrical power, corporations and factories where powered by on-site small-scale power plants.] 
- .large[Today, large scale power plants with efficient transmission networks have powered modern industrial society, allowing electricity to be at everyone's disposal ar reasonable prices]

--

- .heat[Much like electricity the core concept of cloud computing is resource sharing]
---
class: top
# What is cloud computing ?

.fat[definitions:]

>A model for enabling ubiquitious, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or server provider interaction

`r tufte::quote_footer("National Institute of Standards and Technology(NIST) of the US Department of Commerce, 2019")`

--

>Simply put, cloud computing is the delivery of computing services – including servers, storage, databases, networking, software, analytics and intelligence – over the Internet (**"the cloud"**) to offer faster innovation, flexible resources and economies of scale. Typically, you only pay for cloud services you use, helping you lower your operating costs, run your infrastructure more efficiently and scale as your business needs change.

`r tufte::quote_footer("Beginners guide to cloud computing, Microsoft Azure, 2020")`

---
class:top
## Essential characteristics of cloud computing solutions

.heatinline[The follow distinguish cloud computing from other solutions, such as on-site high performance computing servers]

- .large.fancy[On-demand self-service] 
  - A consumer can provision computing capacity as needed without interaction with service provider
- .large.fancy[Broad network access]
  - Computing resources are available to the consumer through the network and can  be accessed from mobile phones, tablets, laptops, and workstations.
- .large.fancy[Resource pooling]
  - Resources are dynamically assigned to customers' needs
- .large.fancy[Rapid elasticity]
  - Capacities can be reconfigured automatically to scale rapidly in response to the changing demand
- .large.fancy[Measured service]
  - The resource utilisation is automatically controlled and optimised by the cloud systems.  The usage is monitored, measured, and reported

---
class: middle

## Why high performance computing and why now?
.salt[A key reason is the regulatory response to the flash crash of 2010]
> On the 6th May, 2010 at 2.45 p.m.(EST), the US stock market experienced a nearly 10% drop in the Dow Jones Industrial Average, only to recover most of ther loss a few minutes later

<iframe width="560" height="315" src="https://www.youtube.com/embed/_ZDEWVJan0s" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
class:inverse
# Flash crashed explained
<img src="img/nyt_flashcrash.png" height="70%" width="70%" class="center">

---
class: middle

## Why high performance computing and why now?

.saltinline[It took the regulatory agencies (SEC) five months to come up with an investigation report on the 2010 flash crash]

.heatinline[In the congressional hearings after the event, the SEC official give the primary reason for the long delay as the volumne of data to be investigated (~20 terabytes)]

.heatinline[HPC scientific computing systems such as the National Research Scientific Computing center(NERSC). routinely work with hundreds of terrabytes in minutes]

.heatinline[After the congressional hearing Lawrence Berkley National Laboratory (LNBL) established the Computational Intelligence and Forecasting Technologies (CIFT) project to promote HPC tools and techniques for analysing of financial times series data]


---
class:middle
background-image: url(img/t1.png)
background-size: cover
---
class:middle
background-image: url(img/t2.png)
background-size: cover
---
class: middle
## QMS Remote analytics Platform (Q-RaP)

- We have recently introduced state-of-the-art cloud computing teaching for the masters students in the Management School

- We have built a high-performance virtual machine in the Azure cloud to expose students to the production-level technologies they will experience in industry.

- SPECIFICATION: A Linux (ubuntu 18.04) operating system (the most popular OS) with 64 vCPUs, 256 GiB of RAM.

- This will allows us to teach 64-128 students concurrently (with toy computational tasks with each student limited to 1vCPU and 4 GiB RAM)

---
class:inverse,top
## Knowledge Gap in *Quant Finance* Industry

<img src="img/gap.jpg" class="center" width="40%">

---
class:middle
# Q-RaP software
.pull-left[
- To help fill this gap we will be using the last production level software on  Q-RaP.

- This be preliminary through the RStudio professional product range

<img src="img/RStudio-Logo.png" width="50%" class="center">

]
.pull-right[
- Programming language knowledge is like a fashion accessory; picking a language to learning over all others can mean you are out of fashion very quick

- When first learning to code it is much better to learning how to integrate languages on a agile platform.
- `r fa(name="r-project")` is an interoperable language with widespread connectivity

<img src="img/interoperableR.png" width="80%" class="center">]

.heatinline[`r fa(name="r-project")` is design as an interperable language connecting many software]

---
class:middle
# Q-RaP software

- The user interface on the server will be power by Rstudio Team Product, the industry version of the free Rstudio IDE for R.

- .fatinline[Learning to integrate programming languages as a quant finance professional is part of the communicative bridge building needed to close the gap between complex models and financial decisions]

- From this product suite we will be using [RStudio Server Pro](https://rstudio.com/products/rstudio-server-pro/) and RStudio connect

>Rstudio Server Pro is the preferred data analysis and integrated development experience for professional R users and data science teams who use R and Python. `r tufte::quote_footer("RStudio Team, 2020")`

---
class:top,center
# Accessing RStudio on Q-RaP

.pull-left[ 
### Steps
1. Open a web browser
2. Navigate to: http://q-rap.qub.ac.uk:8787/
3. login using the credential provided

.heatinline[Note that these credentials are private and can only be accessed by the administrator (Me)]
]
.pull-right[ 
<img src="img/qms_rstudio_login.png" alt="server_login" >

]
---
class:top,center
# Accessing Rstudio Connect on Q-RaP

.pull-left[ 
### Steps
1. Open a web browser
2. Navigate to: http://q-rap.qub.ac.uk
3. Create an account using your <NAME>@qub.ac.uk email
4. Use a recognisable username that identifies you, for example `barry-quinn`
]
.pull-right[ 
<img src="img/rsconnect_hp.png" alt="connect_login" >

]

.fat[We will be using these resources extensively for both growth learning and assessment]

---
class: middle,center
background-image: url(img/title-slide-img.png)
background-size: cover
# A breathing break

<iframe width="560" height="315" src="https://www.youtube.com/embed/PmBYdfv5RSk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
class:middle
# Taxonomy of parallel computing
- .large[Computer processors process instructions sequentially.
- Traditional computing problems are serial by design.
- The birth of multiprocessors (*multicore processors*) has innovated a new type of computing problem:
]
.acid[how to utilise the parallel structure]
- .large[Roughly speaking, multicore processors are equivalent to running multiple computers at a time]
---
class:middle
# Taxonomy of parallel computing
.pull-left.acid[Parallel computing problems in contrast to serial computing problems, refer to the type of problem that can be divided into small Jobs which can be processed simultaneously ]
.pull-right[
**embarrassingly parallel computing**:
```{r embar_parallel,echo=FALSE}
DiagrammeR::grViz("
digraph rmarkdown {
'Input Data'->{Job1,Job2,Job3}
{Job1,Job2,Job3}->'Results'
} 
"
,height = 200
)

```

**nonembarrassingly parallel computing**:
```{r nonembar_parallel,echo=FALSE}
DiagrammeR::grViz("
digraph rmarkdown {
'Input Data'->{Job1,Job2,Job3}
{Job1,Job2,Job3}->'Results'
Job1->Job2[dir='both',label='Information',style='dashed']
Job2->Job3[dir='both',label='Information',style='dashed']
{rank=same; Job1;Job2;Job3}
} 
"
,height = 200
)
```
]
---
class:top

# Taxonomy of parallel computing

.pull-left[

#### Figure 1: embarrassingly parallel computing
```{r embar_parallel1,echo=FALSE}
DiagrammeR::grViz("
digraph rmarkdown {
'Input Data'->{Job1,Job2,Job3}
{Job1,Job2,Job3}->'Results'
} 
"
,height = 200
)

```

#### Figure 2: snonembarrassingly parallel computing
```{r nonembar_parallel1,echo=FALSE}
DiagrammeR::grViz("
digraph rmarkdown {
'Input Data'->{Job1,Job2,Job3}
{Job1,Job2,Job3}->'Results'
Job1->Job2[dir='both',label='Information',style='dashed']
Job2->Job3[dir='both',label='Information',style='dashed']
{rank=same; Job1;Job2;Job3}
} 
"
,height = 200
)
```
]
.pull-right[
-  Based on the dependence structure of sub-Jobs problems parallel computing problems can be further classified into *embarrassingly parallel* and  *non embarrassingly parallel*
- If sub-Jobs are independent then we have an *embarrassingly parallel* problem
- Otherwise we have a  *non embarrassingly parallel* problem
- In figure 1 there is no communication between Jobs, while in figure 2 some communication between Jobs is required
]
---
class:inverse

# Taxonomy of parallel computing
.
- .large[Problems can also be classified by there nature:
- .heatinline[Data parallelism] focuses on distributing data across different processors
- .heatinline[Job parallelism] focuses on distributing execution processes (subtasks) to different processors]
---
class:middle,left
# The serial-parallel scale
.left-column[
```{r, echo=FALSE}
DiagrammeR::grViz("
digraph  {
graph [label='Figure 1: Inherently serial']
'Input Data'->Job1->'Results'->Job2->'More Results'->Job3
} 
"
,height = 400
,options = "margin: auto !important;"
)
```
]

.right-column[

- Another important aspect of parallel computing is whether the parallel computing problem is *scalable*.
- An inherently serial problem cannot be parallelised, e.g. Figure 1
- Scalable problems have either a scalable problem size or scalable parallelism.
- Either the solution time reduces with the increasing of parallelism or the performance of the solution increases with the problem size.
- The elasticity of the computing architecture is the key to the success of the processing of scalable problems

]

---
class:middle
# Example from the finance industry
####.heat[Monte Carlo (MC) Options Pricing]
- Using arbitrage pricing theory, the option price is equal to the expected payoff $V$ discounted by a factor $D$ which can be evaluated via MC method.
The Monte Carlo estimator of option price is given by
$$C_0=D \times \frac{1}{N} \sum_{\omega \in sampleset}V(\omega)$$
where N is the number of sample paths (simulations)

1. The simulation of each price path is independent of other paths, therefore it is easy to parallel process the simulation of different paths on different computing nodes
2. It is a task-parallel in the sense that simulations of each path is a small task.  However it is not data-parallel since there is no data set to be distributed to different computing nodes.
3. The scalable benefit is improved price accuracy as $N$ increases, the error reduction being approximately $1/\sqrt{N}$

---
class:middle
# Example from the finance industry
#####.heat[Backtesting Investment Strategies]

.pull-left[
#### Task-parallel backtesting
- Suppose you need to backtest a basket of different investment strategies to identify the optimal strategies
- The process of each investment strategy is independent of each other and can be run simultaneously.
- Distributing the processing of different strategies to different computing nodes is an *embarrassingly parallel* and *task parallel* implementation.
]
.pull-right[
#### Data-parallel backtesting
- Backtesting on one strategy can also be implemented as *data parallel*
- By generating subsamples from test data set(e.g. by bootstrapping), strategy can be processed on different subsamples simultaneously
- The results on different subsamples is then aggregated to generate the performance and risk report of the strategy
]
---
class:middle
## Business reporting in `r fa('r-project')` for the `r fa(name = "user-ninja")` user
.pull-left[

###<img src="https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/rmarkdown.png" width="10%" style="float:left"/>&nbsp; R Markdown can be used to create: 

- Reports (HTML, PDF, Word)
- Slide Decks (HTML, PowerPoint)
- Web Apps
- Web Pages
- Books
- It is part of the `tidyverse` package

![](https://d33wubrfki0l68.cloudfront.net/61d189fd9cdf955058415d3e1b28dd60e1bd7c9b/9791d/images/rmarkdownflow.png)
]
.pull-right[ 
### Your turn
- Go to server, login in and create new session
- Create a `RMarkdown` file by *File > New File > R Markdown*

<img src="img/qms_rstudio_rmarkdown.png" alt="rmarkdown",height="100"/>
]

---
class:middle
### R Python Interface <img src="https://raw.githubusercontent.com/barryquinn1/reticulate/master/images/reticulated_python.png" width="10%" style="float:right"/>&nbsp;:the `reticulate` package

- In your `Rmd` file, insert a `R code chunk` by clicking Insert and selecting R 
- `r fa('windows')` **Ctrl+Shift+i**
- `r fa('apple')` **Cmd+Shift+i**

```{r python+r set-up}
library(reticulate)
use_python("/Users/barry/anaconda3/bin/python")
```
- Can you insert a `python` code chunk and tell it to print "Hello World"?
--

```{python}
print("Hello World")
````

---
class:middle
# Improving computational performance

- There is a commonly held misconception that both Python and R are relatively slow programming languages and not appropriate to implement computationally demand tasks in finance.
- This criticism stems from the fact that most financial algorithms require loops and loops are slow on interpreted languages such as R and Python.
- Traditionally C or C++, which are compiled programming languages, have been used to speed up loops. 

---
class:middle
# Performance Python
```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
```
- We will consider a number of approaches to speed up typical tasks and algorithms often encountered in finance including:
.bg-gold[
1. **Vectorisation**<br>Making use of Python's vectorisation which can effectively remove a loop structure of a problem
2. **Dynamic Compiling**<br> Using the `Numba` package allows dynamic compilations of pure Python code using [LLVM technology](https://llvm.org/)
3. **Static Compiling**:<br> `Cython` is not only a Python package but a hybrid language that combines Python and C.
4. **Multiprocessing**:<br>Finally we can excute the code in parallel using the `multiprocessing`Python package
]
---
class:middle
# Loops in Python

.panelset[
.panel[.panel-name[Explanation]
- We will start by creating a simple function in Python
- The task is to draws a certain number of random variables and return their average
- Imaginatively, we will call the function `average_py()`

]
.panel[.panel-name[Python Code]

```{python}
import random
from time import process_time
def average_py(n):
  s = 0
  for i in range(n):
      s +=random.random()
  return s/n
```
]

.panel[.panel-name[Output]
```{python}
t_start=process_time()
n=1000000
average_py(n)
t_end=process_time()
print("Elapsed time in seconds:",t_end-t_start)
```

]
]
---
class:top
# Loops using `Numpy`
.panelset[
.panel[.panel-name[Explanation]
- The strength of `Numpy` lies in its vectorisation capabilities.
- Formally, loops vanish on the Python level
- The looping takes place one level deeper based on optimising and compiling routines provided by `Numpy`
- The function `average_np()` makes use of these

]
.panel[.panel-name[Python Code]

```{python}
import numpy as np
def average_np(n):
  s = np.random.random(n)
  return s.mean()
```
]

.panel[.panel-name[Output]
```{python}
t_start=process_time()
n=1000000
average_np(n)
t_end=process_time()
print("Elapsed time in seconds:",t_end-t_start)
```

]
.panel[.panel-name[Vectorisation and Memory]
- The speedup in vectorisation is considerable, almost a factor of 10.
- However this comes at a price of significantly higher memory usage
- The reason is that `Numpy` attains speed by preallocating data that can be processed in the compiled layer.

]
]
---
class:top
# Monte Carlo Simulation in Finance
- As noted earlier, Monte Carlo simulation is an indepensible numerical tool on quantitative finance.
- Banks and other financial institutions using it for pricing and risk management purposes. 
- It is one of the most powerful, flexible, but computationally demanding methods in quantitative finance. 
- This demand has only increased since Basel III, as banks and financial institutions are required to pricing and hedge counterparty risk of complex derivatives.
---
class:top
# Monte Carlo Simulation of Stock Prices
.panelset[
.panel[.panel-name[Explanation]
- In derivative pricing it is standard practice to simulate a set of discrete time series paths for the value of a stock
- We can create a hybrid MC simulator by implementing a Python loop on `ndarray` objects.
- As before we will then use this function, mcs_simulation_py(), to benchmark execution time across a number of performance enhancing approaches.
- Specify, this function simulates geometric Brownian motion price paths using Equation 10-2. in Hilpisch (2018) "Python for Finance".
]
.panel[.panel-name[Python Code for MC simulator]

```{python}
import math
S0=36.
T=1.0
r=0.06
sigma=0.2
def mcs_simulation_py(p):
  M,I = p # M= number of time intervals for discretisation. I = number of paths to simulate. 
  dt = T/M
  S = np.zeros((M+1,I))
  S[0]=S0
  rn = np.random.standard_normal(S.shape)
  for t in range(1,M+1):
    for i in range(I):
      S[t,i] = S[t-1,i]*math.exp((r-sigma**2/2)*dt+sigma*math.sqrt(dt) *rn[t,i])
  return S
```
]

.panel[.panel-name[Execution for MC simulator]

<!-- reticulate::source_python('mcs_simulation.py') -->


```{python}
t_start=process_time()
I=1000
M=100
S = mcs_simulation_py((M,I));
t_end=process_time()
```
```{python}
print("Elapsed time in seconds:",t_end-t_start)
```




]
.panel[.panel-name[Plot 1000 Price Paths in R]
.pull-left[
- `reticulate` allows you to pull objects back into `R` using the `py$OBJECT_NAME` convention.
```
py$S %>% 
  as_tibble() %>%
  mutate(t=row_number()) %>%
  gather(Path,Price,-t) %>%
  ggplot(aes(x=t,y=Price,colour=Path)) + 
  geom_line() +
  theme(legend.position = "none") +
  labs(y="Simulated Prices")
```
]
.pull-right[
```{r plot_python_object, echo=FALSE, fig.retina=3,fig.height=6}
py$S %>% 
  as_tibble() %>%
  mutate(t=row_number()) %>%
  gather(Path,Price,-t) %>%
  ggplot(aes(x=t,y=Price,colour=Path)) + 
  geom_line() +
  theme(legend.position = "none") +
  labs(y="Simulated Prices")
```
]
]
]
---
class:middle
# MC simulator using `Numpy`
.panelset[
.panel[.panel-name[`Numpy` Version]
- The below python code is very similar to the previous except for the highlighted line

```{python}
def mcs_simulation_np(p):
  M,I = p
  dt = T/M
  S = np.zeros((M+1,I))
  S[0]=S0
  rn = np.random.standard_normal(S.shape)
  for t in range(1,M+1):
    for i in range(I):
      S[t,i] = S[t-1,i] * np.exp((r-sigma**2/2) * dt + sigma * math.sqrt(dt) * rn[t,i]) 
  return S
```
]
.panel[.panel-name[Execution time for MC simulator]

```{python}
t_start=process_time()
S = mcs_simulation_np((M,I))
t_end=process_time()
```

```{python}
print("Elapsed time in seconds:",t_end-t_start)
```

- In this instance this is not much faster than the base Python code.

]
]

---
class:top
# MC simulator using `Numba`

```{python}
import numba
mcs_simulation_nb=numba.jit(mcs_simulation_np)
```

### This call includes the compile time overhead

```{python}
t_start=process_time()
S=mcs_simulation_nb((M,I))
t_end=process_time()
print("Elapsed time in seconds:",t_end-t_start)
```

### This call excludes the compile time overhead

```{python}
from time import process_time
t_start=process_time()
S=mcs_simulation_nb((M,I))
t_end=process_time()
print("Elapsed time in seconds:",t_end-t_start)
```

- Again a significant improvement on the raw Python
- After compilation `Numba` is much faster than `Numpy`

---
class: middle
# Multiprocessing

.panelset[
.panel[.panel-name[Explanation]

- As mentioned before, Monte Carlo simulation is a task that lends itself well to parallelisation.
- It is an *embarrassingly* parallel problem with no information shared across sub Jobs.
- In the example we could parallelise the simulation of 1000 paths into 10 processes simulating 100 paths each.
- .saltinline[On the server students are restricted to one vCPU, so what follows is better run on a local multiprocessor machine]
]
.panel[.panel-name[Parallelisation in Python]

- .saltinline[The following code makes use of the `multiprocessing` module and divides the total number of paths to be simulated into small chunks of size $I/p$, where $p>0$]

```{python}
import multiprocessing as mp
pool = mp.Pool(processes=8)
p=10
```

- .saltinline[After all the single tasks are finished, the results are put together in a single `ndarray` object using `np.stack`]

```{python}
t_start=process_time()
S= np.hstack(pool.map(mcs_simulation_np,p*[(M,int(I/p))]))
t_end=process_time()
print("Elapsed time in seconds:",t_end-t_start)
```

- .heatinline[In this instance there is no more speed-up to be observed.]
]
]

---
class:middle 
## The economics of AI tools in Business

- Much like the semiconductor reduced the cost of arithmetic , recent advances in AI make the task of prediction abundant and inexpensive.  
- Advancements have been built around the rubric of machine learning where recent developments in algorithms, computational speed, data storage, and data retrieval have combined to reduce the cost of machine learning predictions.
- The successful deployment of AI tools requires an insight into how best to insert AI into the workflow of a company.  

---
class:inverse
## Consulting example
.pull-left[
- Recently, myself and Dr Byron Graham we recently involved in an consultation exercise on price intelligence for a global price comparison company
- .heatinline[Pricing intelligence involves monitoring competitor prices and updating prices accordingly 
- We we tasked with outlining how to using Machine Learning techniques to improve and scale their current legacy software.
- Opposite is the workflow of the legacy system.
]
.pull-right[
![](img/workflow_pricecompare.png)
]
---
class:middle
## Consulting example
.left-column[
![](img/workflow_pricecompare.png)
]
.right-column[
- Firstly, the workflow should be broken down into "jobs" or "tasks".  
- Each of these tasks usually has a human decision or action attached, which has the potential to be automated via an AI tool.  
- For instance, in figure 1 the company's workflow has two critical decisions:
  1. Given a URL, where on the web page is the product price located?
  2. How can the price be efficiently and dynamically retrieved?
]

---
class:inverse
## Economics of AI: Corporate strategy

.heatinline[
-  A successful corporate AI strategy requires clear and meaningful decomposition of the workflow.
- Each task in the workflow needs to be decomposed in order to see where AI prediction can be inserted.  
- This, in turn, allows estimation of the benefit of enhanced prediction and the cost of generating that prediction.  
- Once reasonable estimates have been made, the potential AI projects can be rank-ordered from highest to lowest return on investment(ROI).  
- Management can then start at the top and implement AI tools as long as the expected ROI makes sense.
]

---
class:middle
## Economic of AI: Decomposing business decisions
.pull-left[
![](img/anatomy_of_a_task.png)
]
.pull-right[
- Figure 2 illustrates the *anatomy of a task*, a diagram used by [Creative Destruction Labs](https://www.creativedestructionlab.com/ ) a world-leading incubator for successful AI start-ups

- When someone makes a decision, they take input data from the world that enables a prediction. 
- The prediction is made possible as training has occurred about relationships between different types of data and which data is most closely associated with a situation. 
- A decision-maker would then combine the prediction with judgement (based on intuition and experience) on what matters to choose appropriate action.  
- The action leads to an outcome which has an associated payoff or reward. 
]

---
class:middle
## Economic of AI: Decomposing business decisions
.pull-left[
![](img/anatomy_of_a_task.png)
]
.pull-right[
- The outcome is the consequence of the decision. 
- It is needed to provide a complete picture. 
- The outcome may also provide feedback to help improve the next prediction.  
- And thus, the cycle of the task repeats.  
]

---
class:middle
## Economic of AI: Decomposing business decisions
.pull-left[
![](img/anatomy_of_a_task.png)

]

.pull-right[
- Reframing decisions in this way places prediction at the centre of the task. 
- The process has three different types of data, input, training and feedback. 
- As there is uncertainty around all prediction, you need judgement when prediction turns out to be wrong.  
- Judgement involves determining the relative payoff associated with each possible outcome, including those with **correct** decisions as well as those associated with mistakes.  

- Uncertainty increases the cost of judging the payoffs for a given decision. 
- Observed outcomes can be used as feedback to inform the next prediction.  
]
---
class:middle
## Economic of AI: Decomposing business decisions
.pull-left[

![](img/anatomy_of_a_task.png)

]

.pull-right[

- By breaking up a decision into elements, we can think about which parts of the human activities will diminish in value and which will increase as a result of enhanced machine prediction.  

--

- As machines substitute for humans in prediction, the value of human prediction will decline. 

--

- Importantly, the other elements of a decision – judgement, data, action – remain, firmly placed in the human domain. 

--

- These are complements to prediction, which means that their value will increase as prediction becomes cheaper. 

--

-In this way, AI tools can create opportunities to exploit expertise in judgement where previously human predictions were so poor as to avoid any decision making (for example, where the default option is always accepted).  

--

- In this case, the demand for human judgement will increase.

]
---
class:middle
# Terminology   
```{r glossary, echo=FALSE}
library(kableExtra)
tibble(Term=c("Computing instances"," Data center","Middelware", "Virtualisation","Cloud bursting","Elastic computing","Wall clock time(WCT)","CPU time"),
       Explanation=c("Refers to a (virtual) server instance that is linked to a computing network to provide computing resource. To offer flexibility to their customers, cloud vendors offer different types of nodes that comprise various combinations of CPU (central processing unit), memory, storage, and networking capacity","A data center comprises a large number of computing nodes and necessary facilities to house the computer system","is the computer software that *glues* software applications with computing hardware. In cloud computing, middleware is used to enable communication and management data","Using computer resources to imitate other computer resources. By virtualisation, users are not locked with specific operating systems, CPU architecture, etc. Middleware and virtualisation are particularly important to ensure on-demand self-service of cloud computing","Cloud computing offers on-demand service. Cloud bursting refers to the process of dynamic deployment of software applications","is a computing service which has the ability to scale resources to meet requirements, e.g. Amazon's EC2 instances","is the human perception of the passage of time from the start to the completion of a task","The amount of time for which a CPU was used for processing instructions of a computer program or operating system, as opposed to, for example, waiting for input/output(I/O) operations or entering low-power (idle) mode.")) %>%
  kbl() %>%
  kable_paper() %>%
  scroll_box(width = "100%", height = "400px")
```

